#!/bin/bash
# shellcheck disable=SC2001

set -euo pipefail

current_dir="$(cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd)"
version=$(<"$current_dir/../VERSION")

echo -e "~~~ :bash: Processing Post-Cache..."

if [[ "${BUILDKITE_PLUGIN_CACHE_DEBUG:-false}" =~ (true|on|1) ]]; then
  set -x
fi

if [ ${BUILDKITE_COMMAND_EXIT_STATUS} -ne 0 ]; then
  echo "--- 🚨 Cache is skipped because step returned ${BUILDKITE_COMMAND_EXIT_STATUS}"
  exit 0
fi

if [[ -n "${BUILDKITE_PLUGIN_CACHE_CACHE_KEY:-}" ]]; then
  AWS_ARGS=""

  if [[ -n "${BUILDKITE_PLUGIN_CACHE_S3_PROFILE:-}" ]]; then
    AWS_ARGS="--profile ${BUILDKITE_PLUGIN_CACHE_S3_PROFILE}"
  fi
  
  # Defaults...
  hasher="sha1sum"
  tar_options="--ignore-failed-read -cf"
  rsync_args="--ignore-missing-args"
  
  if [[ "$OSTYPE" == "darwin"* ]]; then
    hasher="shasum"
    tar_options="-cf"
    rsync_args=""
  fi

  cache_key_prefix=$(echo "$BUILDKITE_PLUGIN_CACHE_CACHE_KEY" | sed -e 's/{.*//')
  template_value=$(echo "$BUILDKITE_PLUGIN_CACHE_CACHE_KEY" | sed -e 's/^[^\{{]*[^A-Za-z]*//' -e 's/.}}.*$//' | tr -d \' | tr -d \")

  if [[ $template_value == *"checksum"* ]]; then
    target="$(echo -e "${template_value/"checksum"/""}" |  tr -d \' | tr -d \" | sed -e 's/^[[:space:]]*//' -e 's/[[:space:]]*$//')"
    result=$(find "$target" -type f | xargs -d'\n' -P0 -n1 $hasher | sort -k 2 | $hasher | awk '{print $1}')
    cache_key="$cache_key_prefix$result"
  else
    cache_key=$BUILDKITE_PLUGIN_CACHE_CACHE_KEY
  fi
  
  paths=()

  if [[ -n "${BUILDKITE_PLUGIN_CACHE_PATHS:-}" ]]; then
    paths+=("$BUILDKITE_PLUGIN_CACHE_PATHS")
  fi

  while IFS='=' read -r path _; do
    if [[ $path =~ ^(BUILDKITE_PLUGIN_CACHE_PATHS_[0-9]+) ]]; then
      paths+=("${!path}")
    fi
  done < <(env | sort)

  if [[ -n "${BUILDKITE_PLUGIN_CACHE_RSYNC_STORAGE:-}" ]]; then

    cache_prefix="${BUILDKITE_PLUGIN_CACHE_RSYNC_STORAGE}/${BUILDKITE_ORGANIZATION_SLUG}/${BUILDKITE_PIPELINE_SLUG}"

    mkdir -p "${cache_prefix}/${cache_key}/"
  elif [[ -n "${BUILDKITE_PLUGIN_CACHE_TARBALL_STORAGE:-}" ]]; then

    cache_prefix="${BUILDKITE_PLUGIN_CACHE_TARBALL_STORAGE}/${BUILDKITE_ORGANIZATION_SLUG}/${BUILDKITE_PIPELINE_SLUG}"

    mkdir -p "${cache_prefix}"
    DAYS="${BUILDKITE_PLUGIN_CACHE_TARBALL_KEEP_MAX_DAYS:-}"
    if [ -n "$DAYS" ] && [ "$DAYS" -gt 0 ]; then
      echo "🗑️ Deleting backups older than ${DAYS} day(s)..."
      find ${cache_prefix} -type f -mtime +${DAYS} -delete
    fi
  else
    TAR_FILE="${cache_key}.tar"
    bucket="${BUILDKITE_PLUGIN_CACHE_S3_BUCKET_NAME}/${BUILDKITE_ORGANIZATION_SLUG}/${BUILDKITE_PIPELINE_SLUG}"
    tkey="${BUILDKITE_ORGANIZATION_SLUG}/${BUILDKITE_PIPELINE_SLUG}"
  fi

  if [ "${#paths[@]}" -eq 1 ]; then
    if [[ -n "${BUILDKITE_PLUGIN_CACHE_RSYNC_STORAGE:-}" ]]; then
      mkdir -p "${cache_prefix}/${cache_key}/${paths[*]}"
      rsync -a $rsync_args --delete "${paths[*]}/" "${cache_prefix}/${cache_key}/${paths[*]}/"
    elif [[ -n "${BUILDKITE_PLUGIN_CACHE_TARBALL_STORAGE:-}" ]]; then
      mkdir -p "${cache_prefix}"
      TAR_FILE="${cache_prefix}/${cache_key}.tar"
      if [ ! -f "$TAR_FILE" ]; then
        tar $tar_options "${TAR_FILE}" "${paths[*]}"
      fi
    else
      echo "🔍 Locating cache on S3: ${paths[*]}"

      TAR_FILE="${cache_key}.tar"
      if [ ! -f "$TAR_FILE" ]; then
        tar $tar_options "${TAR_FILE}" "${paths[*]}"
      fi
      aws s3 cp "$TAR_FILE" "s3://${bucket}/${TAR_FILE}" $AWS_ARGS
      rm -f "${TAR_FILE}"
    fi

  elif [ "${#paths[@]}" -gt 1 ]; then
    if [[ -n "${BUILDKITE_PLUGIN_CACHE_TARBALL_STORAGE:-}" ]]; then
      mkdir -p "${cache_prefix}"
      TAR_FILE="${cache_prefix}/${cache_key}.tar"
      if [ ! -f "$TAR_FILE" ]; then
        tar $tar_options -cf "${TAR_FILE}" "${paths[@]}"
      fi
    elif [[ -n "${BUILDKITE_PLUGIN_CACHE_RSYNC_STORAGE:-}" ]]; then
      for path in "${paths[@]}"; do
        mkdir -p "${cache_prefix}/${cache_key}/${path}"
        rsync -a $rsync_args --delete "${path}/" "${cache_prefix}/${cache_key}/${path}/"
      done
    else
      echo "🔍 Locating cache on S3: ${path}"
      TAR_FILE="${cache_key}.tar"
      if [ ! -f "$TAR_FILE" ]; then
        tar $tar_options "${TAR_FILE}" "${paths[@]}"
      fi
      aws s3 cp "${TAR_FILE}" "s3://${bucket}/${TAR_FILE}" $AWS_ARGS
      rm -f "${TAR_FILE}"
    fi
  fi
else
  echo "🚨 Cache is skipped because no cache key provided"
  exit 0
fi
